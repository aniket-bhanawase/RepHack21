{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "twenty-priest",
   "metadata": {},
   "source": [
    "## Train data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random \n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DATA_DIR = \"D:/learning/tf/EMOTION_DETECTION/data/train\" # 48x48 px image\n",
    "CATEGORIES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    with tqdm(total=len(CATEGORIES)) as pbar_cat:\n",
    "        for CATEGORY in CATEGORIES:\n",
    "            path = os.path.join(DATA_DIR, CATEGORY)\n",
    "            imgs_list = os.listdir(path)\n",
    "            with tqdm(total=len(imgs_list)) as pbar_img:\n",
    "                for img_name in os.listdir(path):\n",
    "                    class_ = CATEGORIES.index(CATEGORY)\n",
    "                    img_array = cv2.imread(os.path.join(path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "                    training_data.append([img_array, class_])\n",
    "                    pbar_img.update(1)\n",
    "            pbar_cat.update(1)\n",
    "            \n",
    "create_training_data()\n",
    "\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "IMG_SIZE = 48\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "with tqdm(total=len(CATEGORIES)) as pbar_t_data:\n",
    "    for features, label in training_data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        pbar_t_data.update(1)\n",
    "\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) #1 for gray scale, 3 for color img0\n",
    "y = np.array(y)\n",
    "\n",
    " # expoet cleaned data\n",
    "\n",
    "pickle_out=open(\"X-{}.pickle\".format(IMG_SIZE), \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out=open(\"y-{}.pickle\".format(IMG_SIZE), \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-influence",
   "metadata": {},
   "source": [
    "## TEST data prep for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pickle\n",
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "TEST_DATA_DIR = \"D:/learning/tf/EMOTION_DETECTION/data/test\" # 48x48 px image\n",
    "CATEGORIES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "testing_data = []\n",
    "\n",
    "def create_testing_data():\n",
    "    for CATEGORY in CATEGORIES:\n",
    "        path = os.path.join(TEST_DATA_DIR, CATEGORY)\n",
    "        for img_name in os.listdir(path):\n",
    "            class_ = CATEGORIES.index(CATEGORY)\n",
    "            img_array = cv2.imread(os.path.join(path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "            testing_data.append([img_array, class_])\n",
    "            \n",
    "create_testing_data()\n",
    "\n",
    "random.shuffle(testing_data)\n",
    "\n",
    "IMG_SIZE = 48\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "\n",
    "for features, label in testing_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "    \n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1) #1 for gray scale, 3 for color img0\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "pickle_out=open(\"X-test-{}.pickle\".format(IMG_SIZE), \"wb\")\n",
    "pickle.dump(X_test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out=open(\"y-test-{}.pickle\".format(IMG_SIZE), \"wb\")\n",
    "pickle.dump(y_test, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-complement",
   "metadata": {},
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "MODEL_DIR = \"./old_models/\"\n",
    "\n",
    "MODEL_NAME = \"emo-analysis-Adam-decay-lr-10-epoch-3-conv-128-nodes-0-dense-1613888403.model\"\n",
    "\n",
    "for model in os.listdir(MODEL_DIR):\n",
    "    print(model)\n",
    "    model = tf.keras.models.load_model(MODEL_DIR + model)\n",
    "    model_eval = model.evaluate(X_test, y_test)\n",
    "    print(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-madonna",
   "metadata": {},
   "source": [
    "## External image predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "IMG_SIZE = 48\n",
    "\n",
    "TEST_DIR_PATH = \"D:/learning/tf/EMOTION_DETECTION/extdata\"\n",
    "\n",
    "MODEL_DIR = \"./old_models/\"\n",
    "\n",
    "#best so far \n",
    "## emo-analysis-Adam-decay-lr-3-conv-128-nodes-1-dense-1613837977.model\n",
    "\n",
    "MODEL_NAME = \"emo-analysis-Adam-decay-lr-3-conv-128-nodes-1-dense-1613837977.model\"\n",
    "\n",
    "CATEGORIES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "def prepare(path):\n",
    "    img_array = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1) # 1:gray scale 3:color image\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_DIR + MODEL_NAME)\n",
    "\n",
    "\n",
    "\n",
    "for img_path in os.listdir(TEST_DIR_PATH):\n",
    "    preprd_img = prepare(os.path.join(TEST_DIR_PATH, img_path))\n",
    "    pred = model.predict([preprd_img])\n",
    "#     print(np.argmax(pred))\n",
    "    print(\"{} - {}\".format(os.path.join(TEST_DIR_PATH, img_path), CATEGORIES[np.argmax(pred)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-disabled",
   "metadata": {},
   "source": [
    "## Live Emotion Detection usng OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time as t\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = 48\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "STRECH = 10\n",
    "\n",
    "CATEGORIES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "COLORS = {\n",
    "     'angry':  (0, 0, 255), \n",
    "     'disgust': (0, 255, 255), \n",
    "     'fear':    (255,145,0), \n",
    "     'happy':   (0, 255, 0), \n",
    "     'neutral': (0, 53, 255), \n",
    "     'sad':     (255, 26, 0), \n",
    "     'surprise':(255, 0, 255)\n",
    "}\n",
    "\n",
    "MODEL_DIR = \"./best/\"\n",
    "MODEL_NAME = \"emo-analysis-Adam-decay-lr-3-conv-128-nodes-1-dense-1613837977.model\" # - best so far\n",
    "\n",
    "# MODEL_DIR = \"./models/\"\n",
    "# MODEL_NAME = \"emo-analysis-Adam-decay-lr-10-epoch-2-conv-256-nodes-1-dense-1613917992.model\"\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_DIR + MODEL_NAME)\n",
    "\n",
    "window_name = 'Image'\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (50, 50)\n",
    "fontScale = 1\n",
    "color = (255, 0, 0) \n",
    "thickness = 2\n",
    "emotions = []\n",
    "while 1:\n",
    "    try:\n",
    "        ret, img = cap.read()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        time_str = str(int(t.time()))\n",
    "        for (x,y,w,h) in faces:\n",
    "            x-=STRECH\n",
    "            y-=STRECH\n",
    "            w+=STRECH*2\n",
    "            h+=STRECH*2\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "    #         roi_color = img[y:y+h, x:x+w]\n",
    "            img_array = cv2.resize(roi_gray, (IMG_SIZE, IMG_SIZE))\n",
    "            img_array = img_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "            org = (x-10, y-10)\n",
    "            pred = model.predict([img_array])\n",
    "            emotion = CATEGORIES[np.argmax(pred)]\n",
    "            emotions.append(emotion)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),COLORS[emotion],2)\n",
    "            img=cv2.putText(img,emotion, org, font,\n",
    "                           fontScale, COLORS[emotion], thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.imwrite(r'./faces/'+'face-'+','.join(emotions)+'.png', img)\n",
    "        emotions.clear()\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-blocking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
